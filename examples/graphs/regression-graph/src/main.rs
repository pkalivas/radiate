use std::time::Duration;

use radiate::{prelude::*, stats::AsciiDashboard};

const MIN_SCORE: f32 = 0.001;

fn main() {
    random_provider::set_seed(90);

    let store = vec![
        (NodeType::Input, vec![Op::var(0)]),
        (NodeType::Edge, vec![Op::weight()]),
        (NodeType::Vertex, vec![Op::sub(), Op::mul(), Op::linear()]),
        (NodeType::Output, vec![Op::linear()]),
    ];

    let engine = GeneticEngine::builder()
        .codec(GraphCodec::directed(1, 1, store))
        .raw_fitness_fn(Regression::new(dataset(), Loss::MSE))
        .minimizing()
        // .subscribe(AsciiDashboardHandler::new(AsciiDashboard::new(
        //     Duration::from_millis(10),
        // )))
        .diversity(NeatDistance::new(0.1, 0.1, 0.3))
        .alter(alters!(
            GraphCrossover::new(0.5, 0.5),
            OperationMutator::new(0.07, 0.05),
            GraphMutator::new(0.1, 0.1).allow_recurrent(false)
        ))
        .build();

    radiate::dashboard(engine)
        .iter()
        // .logging()
        .until_score(MIN_SCORE)
        .last()
        .inspect(display);
}

fn display(result: &Generation<GraphChromosome<Op<f32>>, Graph<Op<f32>>>) {
    for (_, metric) in result.metrics().iter() {
        if let Some(tags) = metric.tags() {
            println!("{tags:?} => {:?}", metric);
        }
    }

    Accuracy::default()
        .named("Regression Graph")
        .on(&dataset().into())
        .loss(Loss::MSE)
        .eval(result.value())
        .inspect(|acc| {
            println!("{result:?}\n{acc:?}\n{}", result.metrics().dashboard());
        });
}

fn dataset() -> impl Into<DataSet> {
    let mut inputs = Vec::new();
    let mut answers = Vec::new();

    let mut input = -1.0;
    for _ in -10..10 {
        input += 0.1;
        inputs.push(vec![input]);
        answers.push(vec![compute(input)]);
    }

    (inputs, answers)
}

fn compute(x: f32) -> f32 {
    4.0 * x.powf(3.0) - 3.0 * x.powf(2.0) + x
}
